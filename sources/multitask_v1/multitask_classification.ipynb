{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "45b50f48-cbee-4fa9-8884-9003d20fe4d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-26T11:50:33.997143Z",
     "iopub.status.busy": "2025-06-26T11:50:33.996835Z",
     "iopub.status.idle": "2025-06-26T11:50:34.002457Z",
     "shell.execute_reply": "2025-06-26T11:50:34.001421Z",
     "shell.execute_reply.started": "2025-06-26T11:50:33.997119Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import (\n",
    "    RobertaTokenizerFast,\n",
    "    RobertaModel,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    AutoConfig,\n",
    ")\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "123b6bde-1b41-4616-8620-1a060e3eeb82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-26T11:21:03.272719Z",
     "iopub.status.busy": "2025-06-26T11:21:03.272474Z",
     "iopub.status.idle": "2025-06-26T11:21:03.278061Z",
     "shell.execute_reply": "2025-06-26T11:21:03.277081Z",
     "shell.execute_reply.started": "2025-06-26T11:21:03.272695Z"
    }
   },
   "outputs": [],
   "source": [
    "id2label_cert = {0: \"Certain\", 1: \"Somewhat certain\", 2: \"Somewhat uncertain\", 3: \"Uncertain\"}\n",
    "label2id_cert = {\"Certain\": 0, \"Somewhat certain\": 1, \"Somewhat uncertain\": 2, \"Uncertain\": 3}\n",
    "\n",
    "id2label_caus = {0: \"Explicitly states: no relation\", 1: \"Causation\", 2: \"Correlation\", 3: \"No mention of a relation\"}\n",
    "label2id_caus = {\"Explicitly states: no relation\": 0, \"Causation\": 1, \"Correlation\": 2, \"No mention of a relation\": 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1eb78f52-473d-4d5b-af00-2f224f2a4f7a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-26T11:21:03.279279Z",
     "iopub.status.busy": "2025-06-26T11:21:03.279036Z",
     "iopub.status.idle": "2025-06-26T11:21:03.283312Z",
     "shell.execute_reply": "2025-06-26T11:21:03.282434Z",
     "shell.execute_reply.started": "2025-06-26T11:21:03.279256Z"
    }
   },
   "outputs": [],
   "source": [
    "model_id = \"roberta-base\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c802cd56-4093-4de0-8072-d7f64507d5c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-26T11:21:03.285765Z",
     "iopub.status.busy": "2025-06-26T11:21:03.285533Z",
     "iopub.status.idle": "2025-06-26T11:21:03.306042Z",
     "shell.execute_reply": "2025-06-26T11:21:03.304793Z",
     "shell.execute_reply.started": "2025-06-26T11:21:03.285742Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = pd.read_csv('../data/causality_cert_train.csv', index_col=0)\n",
    "train_dataset[\"certainty\"] = train_dataset.certainty.map(label2id_cert)\n",
    "train_dataset[\"causality\"] = train_dataset.causality.map(label2id_caus)\n",
    "\n",
    "test_dataset = pd.read_csv('../data/causality_cert_test.csv', index_col=0)\n",
    "test_dataset[\"certainty\"] = test_dataset.certainty.map(label2id_cert)\n",
    "test_dataset[\"causality\"] = test_dataset.causality.map(label2id_caus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e4a8edd-13d5-4b6e-8c64-0cdf3b9511f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-26T11:21:03.308290Z",
     "iopub.status.busy": "2025-06-26T11:21:03.307899Z",
     "iopub.status.idle": "2025-06-26T11:21:03.539697Z",
     "shell.execute_reply": "2025-06-26T11:21:03.538894Z",
     "shell.execute_reply.started": "2025-06-26T11:21:03.308255Z"
    }
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "613e40dd-83b6-419a-9e68-617b1d42883d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-26T11:21:03.541103Z",
     "iopub.status.busy": "2025-06-26T11:21:03.540839Z",
     "iopub.status.idle": "2025-06-26T11:21:03.550066Z",
     "shell.execute_reply": "2025-06-26T11:21:03.548406Z",
     "shell.execute_reply.started": "2025-06-26T11:21:03.541079Z"
    }
   },
   "outputs": [],
   "source": [
    "class ClassificationData(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.dataframe = dataframe.reset_index(drop=True)\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if isinstance(index, (list, np.ndarray)):\n",
    "            # idx is a list of indices -> return a batch dict\n",
    "            batch = [self._getitem_single(i) for i in index]\n",
    "            # batch is list of dicts; collate into dict of tensors:\n",
    "            return {\n",
    "                key: torch.stack([item[key] for item in batch])\n",
    "                for key in batch[0]\n",
    "            }\n",
    "        else:\n",
    "            # single idx\n",
    "            return self._getitem_single(index)\n",
    "\n",
    "    def _getitem_single(self, index):\n",
    "        row = self.dataframe.iloc[index]\n",
    "        text = str(row.finding)\n",
    "        text = \" \".join(text.split())\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            None,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=True\n",
    "        )\n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "        token_type_ids = inputs[\"token_type_ids\"]\n",
    "\n",
    "        return {\n",
    "            'ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long),\n",
    "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
    "            'causality': torch.tensor(row[\"causality\"], dtype=torch.float),\n",
    "            'certainty': torch.tensor(row[\"certainty\"], dtype=torch.float)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e186b1d-d70b-4374-9a39-11799c7312f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-26T11:21:03.551591Z",
     "iopub.status.busy": "2025-06-26T11:21:03.551358Z",
     "iopub.status.idle": "2025-06-26T11:21:03.557151Z",
     "shell.execute_reply": "2025-06-26T11:21:03.556283Z",
     "shell.execute_reply.started": "2025-06-26T11:21:03.551568Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.reset_index(drop=True)\n",
    "test_dataset = test_dataset.reset_index(drop=True)\n",
    "\n",
    "training_set = ClassificationData(train_dataset, tokenizer, 512)\n",
    "testing_set = ClassificationData(test_dataset, tokenizer, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9357bb32-5bf4-4f76-8987-7e8f3d8f528d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-26T11:21:03.558767Z",
     "iopub.status.busy": "2025-06-26T11:21:03.558499Z",
     "iopub.status.idle": "2025-06-26T11:21:03.563960Z",
     "shell.execute_reply": "2025-06-26T11:21:03.563189Z",
     "shell.execute_reply.started": "2025-06-26T11:21:03.558743Z"
    }
   },
   "outputs": [],
   "source": [
    "train_params = {'batch_size': 4,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "test_params = {'batch_size': 4,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "training_loader = DataLoader(training_set, **train_params)\n",
    "testing_loader = DataLoader(testing_set, **test_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb782478-2d14-46eb-ba98-d806dbe85390",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-26T11:21:03.565324Z",
     "iopub.status.busy": "2025-06-26T11:21:03.565098Z",
     "iopub.status.idle": "2025-06-26T11:21:03.572849Z",
     "shell.execute_reply": "2025-06-26T11:21:03.571675Z",
     "shell.execute_reply.started": "2025-06-26T11:21:03.565302Z"
    }
   },
   "outputs": [],
   "source": [
    "class RobertaClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RobertaClass, self).__init__()\n",
    "        self.l1 = RobertaModel.from_pretrained(\"roberta-base\")\n",
    "        self.pre_classifier = torch.nn.Linear(768, 768)\n",
    "        self.dropout = torch.nn.Dropout(0.3)\n",
    "        self.classifier = torch.nn.Linear(768, 8)\n",
    "        self.unflatten = torch.nn.Unflatten(1, (2, 4))\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        output_1 = self.l1(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "        hidden_state = output_1[0]\n",
    "        pooler = hidden_state[:, 0]\n",
    "        pooler = self.pre_classifier(pooler)\n",
    "        pooler = torch.nn.ReLU()(pooler)\n",
    "        pooler = self.dropout(pooler)\n",
    "        pooler = self.classifier(pooler)\n",
    "        output = self.unflatten(pooler)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "174c4204-ef1d-43ac-98be-8a9616da178c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-26T11:21:03.575136Z",
     "iopub.status.busy": "2025-06-26T11:21:03.574743Z",
     "iopub.status.idle": "2025-06-26T11:21:03.579959Z",
     "shell.execute_reply": "2025-06-26T11:21:03.579069Z",
     "shell.execute_reply.started": "2025-06-26T11:21:03.575102Z"
    }
   },
   "outputs": [],
   "source": [
    "# Setting up the device for GPU usage\n",
    "\n",
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b732732-d0f8-406f-963a-0f898d21d531",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-26T11:21:03.581619Z",
     "iopub.status.busy": "2025-06-26T11:21:03.581263Z",
     "iopub.status.idle": "2025-06-26T11:21:05.768187Z",
     "shell.execute_reply": "2025-06-26T11:21:05.767222Z",
     "shell.execute_reply.started": "2025-06-26T11:21:03.581586Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RobertaClass(\n",
       "  (l1): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): RobertaPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=8, bias=True)\n",
       "  (unflatten): Unflatten(dim=1, unflattened_size=(2, 4))\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RobertaClass()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e206b03-c45e-48c8-9f54-ef5522aef0ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-26T11:21:05.769694Z",
     "iopub.status.busy": "2025-06-26T11:21:05.769369Z",
     "iopub.status.idle": "2025-06-26T11:21:05.776933Z",
     "shell.execute_reply": "2025-06-26T11:21:05.775735Z",
     "shell.execute_reply.started": "2025-06-26T11:21:05.769660Z"
    }
   },
   "outputs": [],
   "source": [
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(params=model.parameters(), lr=2e-5, weight_decay=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18a41fed-4930-4287-ac7f-b0d7fd27044c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-26T11:21:05.779561Z",
     "iopub.status.busy": "2025-06-26T11:21:05.779322Z",
     "iopub.status.idle": "2025-06-26T11:21:05.783964Z",
     "shell.execute_reply": "2025-06-26T11:21:05.782821Z",
     "shell.execute_reply.started": "2025-06-26T11:21:05.779538Z"
    }
   },
   "outputs": [],
   "source": [
    "def calcuate_accuracy(preds, targets):\n",
    "    n_correct = (preds==targets).sum().item()\n",
    "    return n_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "751efa69-3906-440f-ad26-7581ec34cff7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-26T11:21:05.785308Z",
     "iopub.status.busy": "2025-06-26T11:21:05.785083Z",
     "iopub.status.idle": "2025-06-26T11:21:05.794455Z",
     "shell.execute_reply": "2025-06-26T11:21:05.793348Z",
     "shell.execute_reply.started": "2025-06-26T11:21:05.785287Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    tr_loss = 0\n",
    "    n_correct_caus = 0\n",
    "    n_correct_cert = 0\n",
    "    nb_tr_steps = 0\n",
    "    nb_tr_examples = 0\n",
    "    model.train()\n",
    "    for _,data in tqdm(enumerate(training_loader, 0)):\n",
    "        ids = data['ids'].to(device, dtype = torch.long)\n",
    "        mask = data['mask'].to(device, dtype = torch.long)\n",
    "\n",
    "        token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "        certainty = data['certainty'].to(device, dtype = torch.long)\n",
    "        causality = data['causality'].to(device, dtype = torch.long)\n",
    "\n",
    "        outputs = model(ids, mask, token_type_ids)\n",
    "        loss_cert = loss_function(torch.squeeze(outputs[:, 0, :]), certainty)\n",
    "        loss_caus = loss_function(torch.squeeze(outputs[:, 1, :]), causality)\n",
    "        loss = loss_cert + loss_caus\n",
    "        tr_loss += loss.item()\n",
    "        big_val, big_idx = torch.max(outputs.data, dim=2)\n",
    "        n_correct_cert += calcuate_accuracy(torch.squeeze(big_idx[:, 0]), certainty)\n",
    "        n_correct_caus += calcuate_accuracy(torch.squeeze(big_idx[:, 1]), causality)\n",
    "\n",
    "        nb_tr_steps += 1\n",
    "        nb_tr_examples+=certainty.size(0)\n",
    "\n",
    "        if _%5000==0:\n",
    "            loss_step = tr_loss/nb_tr_steps\n",
    "            accu_step_caus = (n_correct_caus*100)/nb_tr_examples\n",
    "            accu_step_cert = (n_correct_cert*100)/nb_tr_examples\n",
    "            print(f\"Training Loss per 5000 steps: {loss_step}\")\n",
    "            print(f\"Training Accuracy per 5000 steps: causality - {accu_step_caus}, certainty - {accu_step_cert}\")\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        # # When using GPU\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'The Total Accuracy for Epoch {epoch}: causality - {(n_correct_caus*100)/nb_tr_examples} certainty - {(n_correct_cert*100)/nb_tr_examples}')\n",
    "    epoch_loss = tr_loss/nb_tr_steps\n",
    "    print(f\"Training Loss Epoch: {epoch_loss}\")\n",
    "    print(f\"Training Accuracy Epoch: causality - {(n_correct_caus*100)/nb_tr_examples} certainty - {(n_correct_cert*100)/nb_tr_examples}\")\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "45ed068a-79c6-411e-a1c3-5085282701ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-26T11:21:05.795644Z",
     "iopub.status.busy": "2025-06-26T11:21:05.795421Z",
     "iopub.status.idle": "2025-06-26T11:34:46.434143Z",
     "shell.execute_reply": "2025-06-26T11:34:46.432942Z",
     "shell.execute_reply.started": "2025-06-26T11:21:05.795621Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 2.6448864936828613\n",
      "Training Accuracy per 5000 steps: causality - 50.0, certainty - 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "335it [02:42,  2.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 0: causality - 81.71641791044776 certainty - 0.0\n",
      "Training Loss Epoch: 2.4426621807155326\n",
      "Training Accuracy Epoch: causality - 81.71641791044776 certainty - 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 2.6892056465148926\n",
      "Training Accuracy per 5000 steps: causality - 100.0, certainty - 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "335it [02:44,  2.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 1: causality - 105.3731343283582 certainty - 0.0\n",
      "Training Loss Epoch: 2.1799345030713435\n",
      "Training Accuracy Epoch: causality - 105.3731343283582 certainty - 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 1.8130110502243042\n",
      "Training Accuracy per 5000 steps: causality - 125.0, certainty - 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "335it [02:44,  2.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 2: causality - 122.76119402985074 certainty - 0.0\n",
      "Training Loss Epoch: 1.8945176437719544\n",
      "Training Accuracy Epoch: causality - 122.76119402985074 certainty - 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 1.1493356227874756\n",
      "Training Accuracy per 5000 steps: causality - 175.0, certainty - 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "335it [02:44,  2.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 3: causality - 136.26865671641792 certainty - 0.0\n",
      "Training Loss Epoch: 1.580358878801118\n",
      "Training Accuracy Epoch: causality - 136.26865671641792 certainty - 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 1.2888275384902954\n",
      "Training Accuracy per 5000 steps: causality - 125.0, certainty - 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "335it [02:44,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 4: causality - 149.17910447761193 certainty - 0.0\n",
      "Training Loss Epoch: 1.2997220259993825\n",
      "Training Accuracy Epoch: causality - 149.17910447761193 certainty - 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.ipc_collect()\n",
    "for epoch in range(EPOCHS):\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "98da31bf-1516-4c8b-99d6-3fda0f5ba7a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-26T11:51:06.448197Z",
     "iopub.status.busy": "2025-06-26T11:51:06.447365Z",
     "iopub.status.idle": "2025-06-26T11:51:06.458870Z",
     "shell.execute_reply": "2025-06-26T11:51:06.458118Z",
     "shell.execute_reply.started": "2025-06-26T11:51:06.448170Z"
    }
   },
   "outputs": [],
   "source": [
    "def valid(model, testing_loader):\n",
    "    model.eval()\n",
    "    n_correct_caus = 0; n_wrong_caus = 0; total = 0; tr_loss=0; nb_tr_steps=0; nb_tr_examples=0\n",
    "    n_correct_cert = 0; n_wrong_cert = 0\n",
    "    \n",
    "    targets_caus = []\n",
    "    outputs_caus = []\n",
    "    targets_cert = []\n",
    "    outputs_cert = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for _, data in tqdm(enumerate(testing_loader, 0)):\n",
    "            ids = data['ids'].to(device, dtype = torch.long)\n",
    "            mask = data['mask'].to(device, dtype = torch.long)\n",
    "            token_type_ids = data['token_type_ids'].to(device, dtype=torch.long)\n",
    "            certainty = data['certainty'].to(device, dtype = torch.long)\n",
    "            causality = data['causality'].to(device, dtype = torch.long)\n",
    "            \n",
    "            outputs = model(ids, mask, token_type_ids).squeeze()\n",
    "            loss_cert = loss_function(torch.squeeze(outputs[:, 0, :]), certainty)\n",
    "            loss_caus = loss_function(torch.squeeze(outputs[:, 1, :]), causality)\n",
    "            loss = loss_cert + loss_caus\n",
    "            tr_loss += loss.item()\n",
    "            big_val, big_idx = torch.max(outputs.data, dim=2)\n",
    "            n_correct_cert += calcuate_accuracy(torch.squeeze(big_idx[:, 0]), certainty)\n",
    "            n_correct_caus += calcuate_accuracy(torch.squeeze(big_idx[:, 1]), causality)\n",
    "\n",
    "            outputs_cert.append(big_idx[:, 0].cpu().detach().numpy())\n",
    "            targets_cert.append(certainty.cpu().detach().numpy())\n",
    "            outputs_caus.append(big_idx[:, 1].cpu().detach().numpy())\n",
    "            targets_caus.append(causality.cpu().detach().numpy())\n",
    "            \n",
    "            nb_tr_steps += 1\n",
    "            nb_tr_examples+=big_idx[:, 0].size(0)\n",
    "            \n",
    "            if _%5000==0:\n",
    "                loss_step = tr_loss/nb_tr_steps\n",
    "                # accu_step = (n_correct*100)/nb_tr_examples\n",
    "                print(f\"Validation Loss per 100 steps: {loss_step}\")\n",
    "                # print(f\"Validation Accuracy per 100 steps: {accu_step}\")\n",
    "    epoch_loss = tr_loss/nb_tr_steps\n",
    "    epoch_accu_caus = (n_correct_caus*100)/nb_tr_examples\n",
    "    epoch_accu_cert = (n_correct_cert*100)/nb_tr_examples\n",
    "    print(f\"Validation Loss Epoch: {epoch_loss}\")\n",
    "    print(f\"Validation Accuracy Epoch: caus: {epoch_accu_caus} cert: {epoch_accu_cert}\")\n",
    "    \n",
    "    outputs_caus = np.concatenate(outputs_caus)\n",
    "    targets_caus = np.concatenate(targets_caus)\n",
    "    outputs_cert = np.concatenate(outputs_cert)\n",
    "    targets_cert = np.concatenate(targets_cert)\n",
    "    \n",
    "    print(\"causality\")\n",
    "    print(f1_score(outputs_caus, targets_caus, average=None))\n",
    "    \n",
    "    print(\"certainty\")\n",
    "    print(f1_score(outputs_cert, targets_cert, average=None))\n",
    "    \n",
    "    return epoch_accu_caus, epoch_accu_cert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c9d0634c-5337-4a9b-9810-d8b67360c7bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-26T11:51:06.650319Z",
     "iopub.status.busy": "2025-06-26T11:51:06.649731Z",
     "iopub.status.idle": "2025-06-26T11:51:20.859606Z",
     "shell.execute_reply": "2025-06-26T11:51:20.858855Z",
     "shell.execute_reply.started": "2025-06-26T11:51:06.650294Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00,  5.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss per 100 steps: 2.6681876182556152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "84it [00:14,  5.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss Epoch: 2.657751499896958\n",
      "Validation Accuracy Epoch: caus: 52.395209580838326 cert: 54.49101796407186\n",
      "causality\n",
      "[0.4        0.54008439 0.52132701 0.52      ]\n",
      "certainty\n",
      "[0.67785235 0.5042735  0.36190476 0.19354839]\n",
      "Accuracy on test data: causality = 52.40%, certainty = 54.49%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "acc_caus, acc_cert = valid(model, testing_loader)\n",
    "print(\"Accuracy on test data: causality = %0.2f%%, certainty = %0.2f%%\" % (acc_caus, acc_cert))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb504e80-cb1b-4f56-8664-c98d8f0e10de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
